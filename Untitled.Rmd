---
title: "Midterm Project"
author: "Ekta Chaudhary"
date: "26/03/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F)
knitr::opts_chunk$set(message = F)
```


```{r}
library(tidyverse)
library(readxl)
library(caret)
library(ModelMetrics)
library(glmnet)
library(gam)
library(mgcv)
library(splines)
library(pdp)
library(earth)
library(dplyr)
library(naniar)
library(bnstruct)
library(corrplot)
library(logisticPCA)
library(MASS)
library(e1071)
library(mlbench)
library(pROC)
library(AppliedPredictiveModeling)
```

Reading the Datasets. Adding the column names to the Breast_Cancer dataset.  

```{r}
Diagnosis = 
read_csv('./data/Diagnosis.csv')
Prognosis = 
  read_csv('./data/Prognosis.csv')
Breast_Cancer = 
  read_csv(file = './data/Breast_Cancer.csv' ,col_names = c('id_number','Clump_thickness','Uniformity_of_Cell_Size','Uniformity_of_Cell_Shape','Marginal_Adhesion','Epithelial_Cell_Size','Bare_Nuclei','Bland_Chromatin','Normal_Nucleoli','Mitoses','Class_cancer'))
```

Replacing the missing observations that are denoted by a ? with na and then using KNN imputation to impute the missing values.

```{r}
Breast_Cancer = Breast_Cancer %>% replace_with_na_all(condition = ~.x == '?')
```

```{r}
Breast_Cancer <- knn.impute(as.matrix(Breast_Cancer), k = 10, cat.var = 2:ncol(Breast_Cancer) - 2,
  to.impute = 1:nrow(Breast_Cancer), using = 1:nrow(Breast_Cancer))
```


Creating a data frame called Breast_Cancer.

```{r}
Breast_Cancer <- data.frame(Breast_Cancer)
```

Using ifelse on the column Class_cancer --> If Class_cancer = 4 then it's malignant, else its benign.
Converted the Class_cancer into factors.

```{r}
Breast_Cancer$Class_cancer = as.factor(ifelse(Breast_Cancer$Class_cancer == 4, 'mal','benign'))
Breast_Cancer = Breast_Cancer[,2:11]
```

Creating a correlation plot to check the correlation between the variables.

```{r}
x = model.matrix(Class_cancer~., Breast_Cancer) [,-1]
corrplot(cor(x))
```

Here we are diving the data into training and test data.

```{r}
set.seed(1)
rowTrain <- createDataPartition(y = Breast_Cancer$Class_cancer,
                                p = 2/3,
                                list = FALSE)
```

Logistic Regression:
```{r}
glm.fit <- glm(Class_cancer~., 
               data = Breast_Cancer, 
               subset = rowTrain,
               family = binomial)

contrasts(Breast_Cancer$Class_cancer)
```

We first consider the Bayes classifier (cutoff 0.5) and evaluate its performance on the test data and then plot the test ROC curve.

```{r}
test.pred.prob  <- predict(glm.fit, newdata = Breast_Cancer[-rowTrain,1:9],
                           type = "response")
test.pred <- rep("benign", length(test.pred.prob))
test.pred[test.pred.prob > 0.5] <- "mal"

roc.glm <- roc(Breast_Cancer$Class_cancer[-rowTrain], test.pred.prob)
plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.glm), col = 4, add = TRUE)
```

We can also fit a logistic regression using caret. This is to compare the cross-valiation performance with other models, rather than tuning the model.

```{r}
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
```

```{r}
set.seed(1)
model.glm <- train(x = Breast_Cancer[rowTrain,1:9],
                  y = Breast_Cancer$Class_cancer[rowTrain],
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)
```

```{r}
coef(glm.fit)
```

Regularized logistic regression can be fitted using `glmnet'. We use the `train` function to select the optimal tuning parameters.

```{r}
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 4),
                        .lambda = exp(seq(-4, -2, length = 20)))


set.seed(1)
model.glmn <- train(x = Breast_Cancer[rowTrain,1:9],
                    y = Breast_Cancer$Class_cancer[rowTrain],
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl)

plot(model.glmn, xTrans = function(x) log(x))   

model.glmn$bestTune
```

```{r}
test.pred.prob  <- predict(model.glmn, x = Breast_Cancer[-rowTrain,1:9],
                      method = "glmnet")
```

Here we use the function `lda` in library `MASS` to conduct LDA.

```{r}
library(MASS)

lda.fit <- lda(Class_cancer~., data = Breast_Cancer,
               subset = rowTrain)
plot(lda.fit)
```

Here we are evaluating the test set performance using ROC.

```{r}
lda.pred <- predict(lda.fit, newdata = Breast_Cancer[-rowTrain,])
head(lda.pred$posterior)

roc.lda <- roc(Breast_Cancer$Class_cancer[-rowTrain], lda.pred$posterior[,2], 
               levels = c("benign", "mal"))

plot(roc.lda, legacy.axes = TRUE, print.auc = TRUE)
```

Using caret:
```{r}
set.seed(1)
model.lda <- train(x = Breast_Cancer[rowTrain,1:9],
                   y = Breast_Cancer$Class_cancer[rowTrain],
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)
```

Using KNN:

```{r, warning=FALSE}
set.seed(1)
model.knn <- train(x = Breast_Cancer[rowTrain,1:9],
                   y = Breast_Cancer$Class_cancer[rowTrain],
                   method = "knn",
                   preProcess = c("center","scale"),
                   tuneGrid = data.frame(k = seq(1,50,by = 5)),
                   trControl = ctrl)

ggplot(model.knn)
```
# GLM, Regularized GLM and LDA have relatively good performance.

```{r}
res <- resamples(list(GLM = model.glm, GLMNET = model.glmn, 
                      LDA = model.lda, KNN = model.knn))
summary(res)
```
Now looking at the test set performance.

```{r, warning=FALSE}
lda.pred <- predict(model.lda, newdata = Breast_Cancer[-rowTrain,], type = "prob")[,2]
glm.pred <- predict(model.glm, newdata = Breast_Cancer[-rowTrain,], type = "prob")[,2]
glmn.pred <- predict(model.glmn, newdata = Breast_Cancer[-rowTrain,], type = "prob")[,2]
knn.pred <- predict(model.knn, newdata = Breast_Cancer[-rowTrain,], type = "prob")[,2]


roc.lda <- roc(Breast_Cancer$Class_cancer[-rowTrain], lda.pred)
roc.glm <- roc(Breast_Cancer$Class_cancer[-rowTrain], glm.pred)
roc.glmn <- roc(Breast_Cancer$Class_cancer[-rowTrain], glmn.pred)
roc.knn <- roc(Breast_Cancer$Class_cancer[-rowTrain], knn.pred)

auc <- c(roc.glm$auc[1], roc.glmn$auc[1], roc.lda$auc[1], roc.knn$auc[1])

plot(roc.glm, legacy.axes = TRUE)
plot(roc.glmn, col = 2, add = TRUE)
plot(roc.lda, col = 3, add = TRUE)
plot(roc.knn, col = 6, add = TRUE)
modelNames <- c("glm","glmn","lda","knn")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:6, lwd = 2)
```

